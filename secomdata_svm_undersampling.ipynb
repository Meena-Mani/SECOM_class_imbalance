{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM, Undersampling and Data Cleaning for Imbalanced Data \n",
    "\n",
    "Date created: Nov 16, 2016   \n",
    "Last modified: Nov 23, 2016  \n",
    "Tags: SVM, undersampling, data-cleaning, imbalanced data set, semiconductor data   \n",
    "About: Improve the classification of an imbalanced semicondutor manufacturing data set using a combination of undersampling (the majority class) and data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>I. Introduction</h3>\n",
    "\n",
    "The [SECOM dataset](http://archive.ics.uci.edu/ml/datasets/SECOM) in the  [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml) is semicondutor manufacturing data. There are 1567 records, 590 anonymized features and 104 fails. This makes it an imbalanced dataset with a 14:1 ratio of pass to fails. The process yield has a simple pass/fail response (encoded -1/1).\n",
    "\n",
    "<h4>Objective</h4>\n",
    "We consider some of the different approaches to classify imbalanced data. In previous examples we looked at [one-class SVM](https://github.com/Meena-Mani/SECOM_class_imbalance/blob/master/secomdata_ocsvm.ipynb) and the [weighted Random Forest](https://github.com/Meena-Mani/SECOM_class_imbalance/blob/master/secomdata_rf.ipynb).\n",
    "Data sampling is another strategy where the aim is to rebalance the data set by oversampling the minority class and/or undersampling the majority class. This is done to improve the sensitivity (i.e the true positive rate) of the minority class. We have already looked at [SVM+oversampling using SMOTE](https://github.com/Meena-Mani/SECOM_class_imbalance/blob/master/secomdata_svm_smote.ipynb). For this exercise, we will focus on undersampling and data cleaning methods.\n",
    "\n",
    "<h4>Methodology</h4>\n",
    "The *sklearn* [imblearn toolbox](http://contrib.scikit-learn.org/imbalanced-learn/index.html) has many methods for oversamplng, undersampling and data cleaning. We will use:\n",
    "- random undersampling (of the majority class)\n",
    "- undersampling + data cleaning using Tomek links  \n",
    "- undersampling + data cleaning using the neighborhood cleaning rule  \n",
    "\n",
    "The undersampling or data cleaning step is followed by classification using an SVM. The *imblearn* toolbox has a [pipeline](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.pipeline.Pipeline.html#imblearn.pipeline.Pipeline) method which will be used to chain all the steps. The cross validation is evaluated with the Matthews correlation coeefficient as well as other measures based on the confusion matrix. \n",
    "\n",
    "<h4>Preprocessing</h4>\n",
    "The data represents measurements from a large number of processes or sensors and many of the records are missing. In addition some measurements are identical/constant and so not useful for prediction. We will remove those columns with high missing count or constant values.  \n",
    "The Random Forest variable importance is used to rank the variables in terms of their importance. For the random forest, we will impute the remaining missing values with the median for the column.   \n",
    "We will additionally scale the data that is applied to the SVM. We will use the <i>sklearn preprocessing</i> module for both imputing and scaling.\n",
    "These are the same steps used for the [one-class SVM](https://github.com/Meena-Mani/SECOM_class_imbalance/blob/master/secomdata_ocsvm.ipynb) and a more detailed explanation can be seen there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipe\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef,\\\n",
    "accuracy_score, classification_report\n",
    "\n",
    "from collections import Counter\n",
    "from time import time\n",
    "from __future__ import division\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1567 observations/rows and 590 variables/columns.\n",
      "The ratio of majority class to minority class is 14:1.\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\"\n",
    "secom = pd.read_table(url, header=None, delim_whitespace=True)\n",
    "\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\"\n",
    "y = pd.read_table(url, header=None, usecols=[0], squeeze=True, delim_whitespace=True)\n",
    "\n",
    "print 'The dataset has {} observations/rows and {} variables/columns.' \\\n",
    "       .format(secom.shape[0], secom.shape[1])\n",
    "print 'The ratio of majority class to minority class is {}:1.' \\\n",
    "      .format(int(y[y == -1].size/y[y == 1].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>II. Preprocessing </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the missing values first, dropping columns which have a large number of missing values and imputing values for those that have only a few missing values.\n",
    "The Random Forest variable importance is used to rank the variables in terms of their importance. The [one-class SVM](https://github.com/Meena-Mani/SECOM_class_imbalance/blob/master/secomdata_ocsvm.ipynb) exercise has a more detailed version of these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SECOM data set now has 409 variables.\n"
     ]
    }
   ],
   "source": [
    "# dropping columns which have large number of missing entries \n",
    "\n",
    "m = map(lambda x: sum(secom[x].isnull()), xrange(secom.shape[1]))\n",
    "m_200thresh = filter(lambda i: (m[i] > 200), xrange(secom.shape[1]))\n",
    "secom_drop_200thresh = secom.dropna(subset=[m_200thresh], axis=1)\n",
    "dropthese = [x for x in secom_drop_200thresh.columns.values if \\\n",
    "             secom_drop_200thresh[x].std() == 0]\n",
    "secom_drop_200thresh.drop(dropthese, axis=1, inplace=True)\n",
    "\n",
    "print 'The SECOM data set now has {} variables.'\\\n",
    "      .format(secom_drop_200thresh.shape[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imputing missing values for the random forest\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "secom_imp = pd.DataFrame(imp.fit_transform(secom_drop_200thresh))\n",
    "\n",
    "# use Random Forest to assess variable importance\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=7)\n",
    "rf.fit(secom_imp, y)\n",
    "\n",
    "# sorting features according to their rank\n",
    "\n",
    "importance = rf.feature_importances_\n",
    "ranked_indices = np.argsort(importance)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data for each class: Counter({-1: 1170, 1: 83}) \n",
      "The maj/min class ratio is: 14\n",
      "Test data for each class: Counter({-1: 293, 1: 21}) \n",
      "The maj/min class ratio for the holdout set is: 14\n"
     ]
    }
   ],
   "source": [
    "# split data into train and holdout sets\n",
    "# stratify the sample used for modeling to preserve the class proportions\n",
    "\n",
    "#X_train, X_test, y_train, y_test = tts(secom_imp[ranked_indices[:40]], y, \\\n",
    "X_train, X_test, y_train, y_test = tts(secom_imp[ranked_indices], y, \\\n",
    "                                   test_size=0.2, stratify=y, random_state=5)\n",
    "                                 \n",
    "print 'Train data for each class: {} '\\\n",
    "      .format(Counter(y_train))\n",
    "print 'The maj/min class ratio is: {0:2.0f}' \\\n",
    "      .format(round(y_train[y_train == -1].size/y_train[y_train == 1].size))\n",
    "print 'Test data for each class: {} '\\\n",
    "      .format(Counter(y_test))\n",
    "print 'The maj/min class ratio for the holdout set is: {0:2.0f}' \\\n",
    "      .format(round(y_test[y_test == -1].size/y_test[y_test == 1].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The SVM is sensitive to feature scale so the first step is to center and normalize the data. The train and test sets are scaled separately using the mean and variance computed from the training data. This is done to estimate the ability of the model to generalize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scaling the split data. The holdout data uses scaling parameters \n",
    "# computed from the training data\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_scaled  = pd.DataFrame(standard_scaler.fit_transform(X_train), \\\n",
    "                              index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(standard_scaler.transform(X_test))\n",
    "# Note: we convert to a DataFrame because the plot functions \n",
    "# we will use need DataFrame inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>III. Undersampling </h3>\n",
    "\n",
    "We will use the *Imblearn* [Random Undersampler](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.under_sampling.RandomUnderSampler.html) method to perform random undersampling. Random Undersampling is a simple method where data points are randomly selected and removed from the majority class. While it is an easy way to address class imbalance, the classifier is forced to learn from a smaller data set and may miss certain characteristics of the data.\n",
    "\n",
    "In this section we will look at the following:\n",
    "\n",
    "- Interactive histogram of the undersampled data\n",
    "- Cross-validation with undersampling ratio and SVM rbf kernel parameters\n",
    "- Experimenting with feature set size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Plotting the distribution before and after undersampling </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset distribution: Counter({-1: 1170, 1: 83})\n",
      "Resampled dataset distribution: Counter({-1: 103, 1: 83})\n"
     ]
    }
   ],
   "source": [
    "# undersampling numbers before/after\n",
    "\n",
    "print 'Original dataset distribution: {}'.format(Counter(y_train))\n",
    "ratio = 0.8\n",
    "\n",
    "rus = RandomUnderSampler(ratio=ratio, random_state=7)\n",
    "X_res, y_res = rus.fit_sample(X_train_scaled, y_train)\n",
    "\n",
    "print 'Resampled dataset distribution: {}'.format(Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAFJCAYAAAAc+rO/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1119f0810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting majority class distribution after undersampling\n",
    "# displaying column 4\n",
    "\n",
    "from IPython.html.widgets import interact\n",
    "@interact(ratio=[0.1,1.0])\n",
    "\n",
    "def plot_dist(ratio):\n",
    "    sns.set(style=\"white\", font_scale=1.3) \n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "    rus = RandomUnderSampler(ratio=ratio, random_state=7)\n",
    "    X_res, y_res = rus.fit_sample(X_train_scaled, y_train)\n",
    "\n",
    "    X_res_df = pd.DataFrame(X_res)\n",
    "\n",
    "    ax = sns.distplot(X_train_scaled[4][y_train == -1], color='darkorange', \\\n",
    "                  kde=False, label='before')\n",
    "    ax = sns.distplot(X_res_df[4][y_res == -1], color='b',  \\\n",
    "                  kde=False, label='after')         \n",
    "\n",
    "    ax.set_ylim([0, 180])\n",
    "    ax.set(xlabel='')\n",
    "    ax.legend(title='Ratio = {}'.format(ratio))\n",
    "    plt.title('Majority class distribution before and after undersampling')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cross-validation </h4>\n",
    "\n",
    "The usual way to select parameters is via grid-search and cross-validation (CV). We will do a grid search over undersampling ratios, and the SVM rbf kernel tuning parameters. The five-fold CV is stratified so for each fold, the sampling ratios are preserved.   \n",
    "The *imblearn package* includes a [pipeline](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.pipeline.Pipeline.html#imblearn.pipeline.Pipeline) module which allows one to chain transformers, resamplers and estimators. We use the pipeline to chain undersampling method with the SVM classifier.  \n",
    "We will set-up a CV function to test out different undersampling methods. We will also vary the number of features.\n",
    "\n",
    "The default CV scoring is based on the accuracy. When the classes are imbalanced, the true negative term (the accuracy of the majority class) dominates. Often, there is a high cost associated with the misclassification of the minority class, and in those cases alternative [scoring measures](http://scikit-learn.org/stable/modules/model_evaluation.html) such as the [F1](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) and [$F_{\\beta}$](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html) scores or the [Matthews Correlation Coefficient (MCC)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) (which uses all four values of the confusion matrix) are used. We will score the cross-validation using the MCC. We will also look at the True Positive Rate (accuracy of the minority class alone), the Accuracy and the confusion matrix when interpreting results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h5>CV setup</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# defining the MCC metric to assess cross-validation\n",
    "\n",
    "def tpr_score(y_true, y_pred):\n",
    "    tprate = float(cm[1][1])/np.sum(cm[1])\n",
    "    return tprate\n",
    "\n",
    "def mcc_score(y_true, y_pred):\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    return mcc\n",
    "    \n",
    "mcc_scorer = make_scorer(mcc_score, greater_is_better=True)\n",
    "tpr_scorer = make_scorer(tpr_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print classification results\n",
    "\n",
    "def test_results(y_test, y_predicted):\n",
    "\n",
    "    print '\\nThe accuracy is: {0:4.2} ' \\\n",
    "    .format(accuracy_score(y_test, y_predicted))\n",
    "\n",
    "    print '\\nThe confusion matrix: '\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    print cm\n",
    "\n",
    "    print '\\nThe True Positive rate is: {0:4.2}' \\\n",
    "    .format(float(cm[1][1])/np.sum(cm[1]))\n",
    "\n",
    "    print '\\nThe Matthews correlation coefficient: {0:4.2f} \\n' \\\n",
    "    .format(matthews_corrcoef(y_test, y_predicted))\n",
    "\n",
    "    print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid search cross-validation function\n",
    "\n",
    "def sampling_gridcv(samp_method, nfeatures):\n",
    "      \n",
    "    X_train_ = X_train_scaled.iloc[:,:nfeatures]\n",
    "    X_test_ = X_test_scaled.iloc[:,:nfeatures]\n",
    "    \n",
    "    add_parameters = dict()\n",
    "    if samp_method == 'rus':\n",
    "        sampling = RandomUnderSampler(random_state=7)\n",
    "        #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "        add_parameters = dict(samp__ratio = np.arange(1,11)*0.1)\n",
    "    elif samp_method == 't1':\n",
    "        sampling = TomekLinks(random_state=7)\n",
    "    elif samp_method == 'ncr':\n",
    "        sampling = NeighbourhoodCleaningRule(random_state=7)\n",
    " \n",
    "\n",
    "    estimators = [('samp', sampling),\n",
    "                  ('clf', SVC(probability=True, random_state=7))]\n",
    "    \n",
    "    parameters = dict(clf__C =[1, 10, 50, 100, 200],\n",
    "                      clf__gamma=[.04, .05, .06, .07])\n",
    "    parameters.update(add_parameters)\n",
    "\n",
    "    pipe = ImbPipe(estimators)\n",
    "    print pipe\n",
    "\n",
    "    # stratified K-fold cross-validation\n",
    "    cv = GridSearchCV(pipe, param_grid = parameters, cv =5, scoring=mcc_scorer)\n",
    "    start = time()\n",
    "    cv.fit(X_train_, y_train)\n",
    "    print '\\nGridSearchCV took {} seconds for {} candidate parameter settings.'\\\n",
    "    .format(time() - start, len(cv.grid_scores_))\n",
    "    y_predicted = cv.predict(X_test_)\n",
    "    #probas_ = cv.predict_proba(X_test_)\n",
    "    print '\\nThe best CV parameters are: {}' .format(cv.best_params_)\n",
    "    \n",
    "    # print test results using best parameters\n",
    "    test_results(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>CV Results</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('samp', RandomUnderSampler(random_state=7, ratio='auto', replacement=True,\n",
      "          return_indices=False)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=7, shrinking=True, tol=0.001,\n",
      "  verbose=False))])\n",
      "\n",
      "GridSearchCV took 48.9249770641 seconds for 200 candidate parameter settings.\n",
      "\n",
      "The best CV parameters are: {'clf__gamma': 0.04, 'samp__ratio': 0.90000000000000002, 'clf__C': 1}\n",
      "\n",
      "The accuracy is: 0.75 \n",
      "\n",
      "The confusion matrix: \n",
      "[[227  66]\n",
      " [ 11  10]]\n",
      "\n",
      "The True Positive rate is: 0.48\n",
      "\n",
      "The Matthews correlation coefficient: 0.15 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.95      0.77      0.85       293\n",
      "          1       0.13      0.48      0.21        21\n",
      "\n",
      "avg / total       0.90      0.75      0.81       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random undersampling with 40 features\n",
    "\n",
    "sampling_gridcv('rus', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('samp', RandomUnderSampler(random_state=7, ratio='auto', replacement=True,\n",
      "          return_indices=False)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=7, shrinking=True, tol=0.001,\n",
      "  verbose=False))])\n",
      "\n",
      "GridSearchCV took 96.4308919907 seconds for 200 candidate parameter settings.\n",
      "\n",
      "The best CV parameters are: {'clf__gamma': 0.04, 'samp__ratio': 0.80000000000000004, 'clf__C': 1}\n",
      "\n",
      "The accuracy is: 0.81 \n",
      "\n",
      "The confusion matrix: \n",
      "[[245  48]\n",
      " [ 13   8]]\n",
      "\n",
      "The True Positive rate is: 0.38\n",
      "\n",
      "The Matthews correlation coefficient: 0.14 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.95      0.84      0.89       293\n",
      "          1       0.14      0.38      0.21        21\n",
      "\n",
      "avg / total       0.90      0.81      0.84       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_gridcv('rus', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('samp', RandomUnderSampler(random_state=7, ratio='auto', replacement=True,\n",
      "          return_indices=False)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=7, shrinking=True, tol=0.001,\n",
      "  verbose=False))])\n",
      "\n",
      "GridSearchCV took 126.518301964 seconds for 200 candidate parameter settings.\n",
      "\n",
      "The best CV parameters are: {'clf__gamma': 0.04, 'samp__ratio': 0.90000000000000002, 'clf__C': 10}\n",
      "\n",
      "The accuracy is: 0.87 \n",
      "\n",
      "The confusion matrix: \n",
      "[[265  28]\n",
      " [ 14   7]]\n",
      "\n",
      "The True Positive rate is: 0.33\n",
      "\n",
      "The Matthews correlation coefficient: 0.19 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.95      0.90      0.93       293\n",
      "          1       0.20      0.33      0.25        21\n",
      "\n",
      "avg / total       0.90      0.87      0.88       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_gridcv('rus', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on initial experiments and the results of the CV above, undersampling with higher ratios like 0.8, 0.9, and 1.0 give higher MCC and True Positive values than lower ratios.\n",
    "\n",
    "We will now run a simpler grid-search over C and gamma using the following parameters:\n",
    "- ratio of 1.0 \n",
    "- number of features = 40\n",
    "- C = 1, 5, 7, 10\n",
    "- gamma = 0.04, 0.05, 0.06\n",
    "\n",
    "(When ratio is included as a grid-search parameter, the MCC and TPR scores are consistently lower. This requires some investigation since the size of the CV folds should not be affected by the complexity of the grid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 0.38 seconds for 12 candidate parameter settings.\n",
      "\n",
      "The best CV parameters are: {'C': 1, 'gamma': 0.06}\n",
      "\n",
      "The accuracy is:  0.7 \n",
      "\n",
      "The confusion matrix: \n",
      "[[206  87]\n",
      " [  6  15]]\n",
      "\n",
      "The True Positive rate is: 0.71\n",
      "\n",
      "The Matthews correlation coefficient: 0.22 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.97      0.70      0.82       293\n",
      "          1       0.15      0.71      0.24        21\n",
      "\n",
      "avg / total       0.92      0.70      0.78       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Second CV (using best CV parameters from previous run)\n",
    "\n",
    "ratio = 1.0\n",
    "\n",
    "X_train_ = X_train_scaled.iloc[:,:40]\n",
    "X_test_ = X_test_scaled.iloc[:,:40]\n",
    "\n",
    "rus = RandomUnderSampler(ratio=ratio, random_state=7)\n",
    "X_res, y_res = rus.fit_sample(X_train_, y_train)\n",
    "\n",
    "clf = SVC(random_state=7)\n",
    "\n",
    "param_grid = {\"C\": [1, 5, 7, 10],\n",
    "              \"gamma\": [0.04, 0.05, 0.06]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, scoring=mcc_scorer)\n",
    "start = time()\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "     % (time() - start, len(grid_search.grid_scores_)))\n",
    "print '\\nThe best CV parameters are: {}' .format(grid_search.best_params_)\n",
    "\n",
    "# using model with best parameters on test set\n",
    "y_predicted = grid_search.predict(X_test_)\n",
    "test_results(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an overall accuracy of 0.7 is acceptable, with random undersampling, we can get a TPR and MCC in the 0.71 and 0.22 range. These are the highest values obtained so far from experiments with sampling and cost-sensitive learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>IV. Data Cleaning + Undersampling </h3>\n",
    "\n",
    "These methods emphasize data cleaning over data reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. Tomek Links</h4>\n",
    "\n",
    "If a pair of minimally distanced nearest neighbors are of opposite classes, they are said to form a Tomek link <a href=\"#ref1\">[1]</a> <a href=\"#ref3\">[3]</a> . Tomek links (TL) are present both at class boundaries or when there is noise within a class. TL are used to cleanup the data set and establish well-defined class clusters and boundaries. We will perform a gridsearch CV using the *Imblearn* [Tomek Links](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.under_sampling.TomekLinks.html#imblearn.under_sampling.TomekLinks) method along with the SVM classifier in the section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset distribution: Counter({-1: 1170, 1: 83})\n",
      "Resampled dataset distribution: Counter({-1: 1151, 1: 83})\n"
     ]
    }
   ],
   "source": [
    "# Number of elements before/after TL\n",
    "\n",
    "print 'Original dataset distribution: {}'.format(Counter(y_train))\n",
    "\n",
    "tl = TomekLinks(random_state=7)\n",
    "X_res, y_res = tl.fit_sample(X_train_scaled, y_train)\n",
    "\n",
    "print 'Resampled dataset distribution: {}'.format(Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('samp', TomekLinks(n_jobs=-1, random_state=7, return_indices=False)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=7, shrinking=True, tol=0.001,\n",
      "  verbose=False))])\n",
      "\n",
      "GridSearchCV took 37.1053049564 seconds for 20 candidate parameter settings.\n",
      "\n",
      "The best CV parameters are: {'clf__gamma': 0.04, 'clf__C': 50}\n",
      "\n",
      "The accuracy is: 0.93 \n",
      "\n",
      "The confusion matrix: \n",
      "[[289   4]\n",
      " [ 18   3]]\n",
      "\n",
      "The True Positive rate is: 0.14\n",
      "\n",
      "The Matthews correlation coefficient: 0.22 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.94      0.99      0.96       293\n",
      "          1       0.43      0.14      0.21        21\n",
      "\n",
      "avg / total       0.91      0.93      0.91       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_gridcv('t1', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. Neighborhood Cleaning Rule</h4>\n",
    "\n",
    "The Neighborhood Cleaning Rule (NCL) is based on a 2001 paper by Laurikkala <a href=\"#ref4\">[4]</a>. It is a combination of ENN (edited nearest neighbor where data points that differ from two of their three nearest neighbors are removed) and Tomek links. NCL emphasizes data cleaning over data reduction with the view that the quality of classification does not necessarily depend on the size of the class.  \n",
    "We will perform a gridsearch CV using the *Imblearn* [Neighborhood Cleaning Rule](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.under_sampling.NeighbourhoodCleaningRule.html#imblearn.under_sampling.NeighbourhoodCleaningRule) method along with the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset distribution: Counter({-1: 1170, 1: 83})\n",
      "Resampled dataset distribution: Counter({-1: 1039, 1: 83})\n"
     ]
    }
   ],
   "source": [
    "# Number of elements before/after NCL\n",
    "\n",
    "print 'Original dataset distribution: {}'.format(Counter(y_train))\n",
    "\n",
    "ncr = NeighbourhoodCleaningRule(random_state=7)\n",
    "X_res, y_res = ncr.fit_sample(X_train_scaled, y_train)\n",
    "\n",
    "print 'Resampled dataset distribution: {}'.format(Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('samp', NeighbourhoodCleaningRule(n_jobs=-1, random_state=7, return_indices=False,\n",
      "             size_ngh=3)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=7, shrinking=True, tol=0.001,\n",
      "  verbose=False))])\n",
      "\n",
      "GridSearchCV took 48.4742040634 seconds for 20 candidate parameter settings.\n",
      "\n",
      "The best CV parameters are: {'clf__gamma': 0.04, 'clf__C': 10}\n",
      "\n",
      "The accuracy is: 0.92 \n",
      "\n",
      "The confusion matrix: \n",
      "[[284   9]\n",
      " [ 17   4]]\n",
      "\n",
      "The True Positive rate is: 0.19\n",
      "\n",
      "The Matthews correlation coefficient: 0.20 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.94      0.97      0.96       293\n",
      "          1       0.31      0.19      0.24        21\n",
      "\n",
      "avg / total       0.90      0.92      0.91       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_gridcv('ncr', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>V. Discussion</h3>\n",
    "\n",
    "In our experiments, the simple Random Undersampling method gave much better results (with respect to the TPR of the minority class) than the TL and NCL methods which emphasize data cleaning. Furthermore, the undersampling also gave better results than [Oversampling with SMOTE](https://github.com/Meena-Mani/SECOM_class_imbalance/blob/master/secomdata_svm_smote.ipynb). The NCL method which incorporates TL gave marginally better results than using TL alone.\n",
    "\n",
    "We expect a combination of oversampling, undersampling, data cleaning and boosting to give the best classification results for the minority class.\n",
    "(writeup to be completed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>VI. References and Further Reading </h3>\n",
    "\n",
    "<a name=\"ref1\"></a>[1] [H. He and E. A. Garcia, Learning from Imbalanced Data, IEEE Trans. Knowledge and Data Engineering, vol. 21, issue 9, pp. 1263-1284, 2009. ](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning.pdf)\n",
    "\n",
    "<a name=\"ref2\"></a>[2] [Lecture Notes based on Learning from Imbalanced Data by Haibo He](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning_lecturenotes.pdf)\n",
    "\n",
    "<a name=\"ref3\"></a>[3] [I. Tomek, Two modifications of CNN, In Systems, Man, and Cybernetics, IEEE Transactions on, vol. 6, pp 769-772, 1976.](http://sci2s.ugr.es/keel/dataset/includes/catImbFiles/1976-Tomek-IEEETSMC.pdf)\n",
    "\n",
    "<a name=\"ref4\"></a>[4] [Laurikkala, Jorma. \"Improving identification of difficult small classes by balancing class distribution.\" Conference on Artificial Intelligence in Medicine in Europe. Springer Berlin Heidelberg, 2001.](http://sci2s.ugr.es/keel/pdf/algorithm/congreso/2001-Laurikkala-LNCS.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FAAC58; margin-left: 0px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;\">\n",
    "\n",
    "\n",
    "Author:  Meena Mani  <br>\n",
    "email:   meenas.mailbag@gmail.com   <br> \n",
    "twitter: @meena_uvaca    <br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
